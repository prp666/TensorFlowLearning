{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "598c1dd8-6c74-41ad-8167-a177cf61c70b",
   "metadata": {},
   "source": [
    "## In Tensorflow.keras_learn(1) we have leraned how to compile, fit, how to build a model by keras.Moudle class, keras.Sequential, Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57c738a-5846-4fad-b85d-b3d21a027ee7",
   "metadata": {},
   "source": [
    "### Now it's time to learn more, First we will learn how to modify hyperparameters in the model bu using `Keras Tuner`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cbb7bf-5ed3-429a-bd5b-2e461b62e750",
   "metadata": {},
   "source": [
    "#### First let's know what is hyperparameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909cf9b7-5de2-46ad-a934-8d838c3119ec",
   "metadata": {},
   "source": [
    "The hypterparameters are the parameters which won't changed while training, they control both training progress and parameters of model topo, they has two kinds:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098c0f58-7202-4839-a313-7e372a887f9a",
   "metadata": {},
   "source": [
    "1. Model Hyperparameters: This kind of hyperparameter will infuence the model complexity, like the width of hidden layer and the number of it, has the model using `Dropout`, `BatchNorm`? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15cfa17-a592-4bc7-a3bf-275bda676628",
   "metadata": {},
   "source": [
    "2. Algorithm Hyperparameters: Have influence in algotithm's speed and quality, like the `learning rate` and the k of `knn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c440bf38-7189-4420-82da-acf1d1c740c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1829362d-075b-41d3-a9d5-147932c07804",
   "metadata": {},
   "source": [
    " **The Tuner need be installed by pip**\n",
    "\n",
    " To make sure we only installed this in visual enviroment, we need to install it by command line, beacuase I am using the Raspberry pi for running this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225e8596-57d9-4582-afef-c415f9007f95",
   "metadata": {},
   "source": [
    "#### The command in python is `pip install -U keras-tuner`, the `-U` is upgrade if there's latest one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42785281-71eb-4413-be5a-a7f85b28e0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b425dd-5e74-45fb-b53c-1c9d0bb3cc08",
   "metadata": {},
   "source": [
    "We download Fashion MNIST dataset for this mission, the dataloading will be covered later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffe55419-2207-4afb-a4c4-74460705281f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "(img_train, lable_train), (img_test, lable_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea02f868-2c18-4570-be94-d4dc23733bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "print(len(img_train))\n",
    "print(len(lable_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6ebe62f-ac36-4044-8ce3-dc217d284276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(img_test))\n",
    "print(len(lable_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8843376c-afaf-472a-b8db-91c9cde1f33d",
   "metadata": {},
   "source": [
    "Now We need normalize the data to `0-1`, but by the way we need to know the dtype, because lots of the model only accept float32 or float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a56312b3-d030-4c35-ae5b-013c619e1eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_train[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce1c6a9c-3d5a-49b9-a87d-185a9493ba8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_test[0].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f456a766-fdf4-4af6-b1bb-a32e1513315f",
   "metadata": {},
   "source": [
    "The datatype is unsigned int 8-bit, which usually used in images, because this do not has symble like plus or minus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e25d341-200d-4acc-87a8-567d97341b87",
   "metadata": {},
   "source": [
    "**Because data which load by `keras.datasets`, it's always numpy array, so we can use `astype()` method for changing dtype, this can only used by numpy array, if the data is `tensorflow.tensors`, we can use `cast()` to change the dtype**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d943d250-fc42-43a5-b8b9-fde1b4994e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68ec6d66-ad51-4fee-9bc2-2292b16a947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = img_train.astype(np.float32) / 255.0\n",
    "img_test = img_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd81df15-6c67-443b-b404-0d899fe8de84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_train[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29085684-ae08-46a5-883a-8e386139b3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_test[0].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febf6ff2-2fb8-4eae-8101-79446c04941a",
   "metadata": {},
   "source": [
    "### Now we need to define hyperparameter model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65377bba-bbb0-47cb-8811-7b365829425c",
   "metadata": {},
   "source": [
    "We not only need to define the model but also need to define the hyperparameter's searching space, we call the model and the configuration together \"hyperparameter searching model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3549b5f0-7240-43af-8cec-8942f4bb767f",
   "metadata": {},
   "source": [
    "There are two kinds of method to define a hyperparameter searching model:\n",
    "\n",
    "1. Using `model_builder(hp)` function for creating, `hp` is `keras_tuner.Hyperparameters()`'s object, which will automatically input by keras_tuner when calling `model_builder()`\n",
    "\n",
    "\n",
    "2. Using `keras Tuner API`, inside there's one `HyperModel` class, we can subclassing(extend, override) this class to create hyperparameter model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4412e4f0-4609-44c8-a808-73279a05a8ec",
   "metadata": {},
   "source": [
    "For **computer vision**, can using `HyperXception`, `HyperResNet` for finding best hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7895f97-292d-4e53-b3c3-cf913b31e3fe",
   "metadata": {},
   "source": [
    "#### The First method: Create a hyperparameter model by `model_builder(hp)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7ee1ec8-ee47-47a5-a995-e147d7011ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(28, 28)))\n",
    "    model.add(keras.layers.Flatten())\n",
    "\n",
    "    # Now define the hyperparameters range of hidden layer, the output number of the hidden layer\n",
    "    hp_units = hp.Int(\"units\", min_value=32, max_value=512, step=32)\n",
    "    model.add(keras.layers.Dense(units=hp_units, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(10))\n",
    "\n",
    "    # Now define the hyperparameters range of learning rate for optimizer\n",
    "    hp_learning_rate = hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "        # from_logits = True means input is logits, we haven't use softmax in the last layer, keras will helps us calculating possibilities\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b715e5-e4f3-4d26-98a6-0bc9a72799c5",
   "metadata": {},
   "source": [
    "**Careful that we have added the name=\"accuracy\" in the metrics, because we haven't use \"Accuracy\", the program need specify then can find it**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3323e643-25db-4ee9-b18d-9f72b750d703",
   "metadata": {},
   "source": [
    "#### In the cell upward is method one, create a method called model_builder, there are something need to be noticed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c357e35-7029-4d9c-a76c-1cb5cc77fc44",
   "metadata": {},
   "source": [
    "1. For everymodel build by `tensorflow.keras`, we shoudn't use the `input_size` parameter now, the tensorflow official suggests using `keras.layers.Input()` to specify the inputsize.\n",
    "\n",
    "2. The hp, is an object which will be automatically created by `keras_tuner.Hyperparameters()`, this object covers useful classes we need in hyperparameter selecting.\n",
    "\n",
    "3. The hyperparameters in hiddenlayers and in algorithms can be changed by keras_tuner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcc565a-7c47-4d6c-ba69-d58c2c79966a",
   "metadata": {},
   "source": [
    "**The useful classes of object `hp`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef5077f-6f84-41f4-894b-0ce7041eb408",
   "metadata": {},
   "source": [
    "1. `hp.Int(name, min_value, max_value, step)`: This class will create a list of int value range from min_value to max_value, and we can also specify step, `eg:hp.Int(\"dense1\", 1, 10, 2) gives hyperparameters : [1, 3, 5, 7, 9]`\n",
    "\n",
    "2. `hp.Float(name, min_value, max_value, step, sampling)`: This class will create a list of float value range from min_value to max_value, also can specify the step, `parameter sampling` means how to select a hyperparameter, there are usually two values, `\"linear\"` means select value uniformed, good for **normalize, dropout**, `\"log\"` will first put value in log space and select, which perform well on **learning_rate**\n",
    "\n",
    "3. `hp.Choice(name, values)`: This class provides several values but the model or the algorithm only select one of them in one searching epoch, `eg:hp.choice(\"activation_fn\", [\"relu\", \"sigmoid\", \"softmax\", \"tanh\"])`\n",
    "\n",
    "\n",
    "There are more functions inside, but from now these are enough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35636add-8a49-4680-8823-ad2fa13fb1a6",
   "metadata": {},
   "source": [
    "#### The second kind of method is subclassing the class `HyperModel`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad88723-0148-442f-8ddb-9b992b7017d1",
   "metadata": {},
   "source": [
    "The HyperModel is a abstract class of keras_tuner, we need to override the function `build(self, hp)` and define both the model and the hyperparameters' searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c54950c-7651-4d60-848e-077d10b530e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "938277b2-29ca-4676-bca5-1ca7ba163b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(kt.HyperModel):\n",
    "    \n",
    "    def build(self, hp):\n",
    "        inputs = keras.layers.Input(shape=(28, 28))\n",
    "        x = keras.layers.Flatten()(inputs)\n",
    "\n",
    "        # Define model Hyperparameters \n",
    "        units = hp.Int(\"units\", min_value=64, max_value=512, step=64)\n",
    "        dropout = hp.Float(\"dropout\", min_value=0.0, max_value=0.6, step=0.1)\n",
    "\n",
    "        x = keras.layers.Dense(units=units, activation=\"relu\")(x)\n",
    "        x = keras.layers.Dropout(dropout)(x)\n",
    "        outputs = keras.layers.Dense(10)(x)\n",
    "\n",
    "        model = keras.Model(inputs, outputs)\n",
    "\n",
    "        # Now the model has beem built, we need define algorithms' hyperparameters\n",
    "        optimizer_name = hp.Choice(\"optimizer\", [\"adam\", \"sgd\"])\n",
    "        if optimizer_name==\"adam\":\n",
    "            learning_rate = hp.Choice(\"learning_rate_adam\", [1e-3, 5e-4, 1e-4])\n",
    "            optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "        else:\n",
    "            learning_rate = hp.Choice(\"learning_rate_sgd\", [1e-2, 5e-3, 1e-3])\n",
    "            momentum = hp.Choice(\"momentum\", [0.0, 0.9])\n",
    "            optimizer = keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")]\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5863fcab-ed29-459a-97c7-7829187327e5",
   "metadata": {},
   "source": [
    "So the second method is similar with the first one, but the first one is very convinent, the second one can also do hyperparameter change with `model.fit()`, find the batch_size, callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83195520-d81a-4602-b673-b115f7592b4b",
   "metadata": {},
   "source": [
    "**We can find there are few same features of each method, both will create model, define hyperparameters(model and algorithm), and compile the model, prepare for the training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a94b00-4dfc-4d74-a2e5-935cfb9adf3f",
   "metadata": {},
   "source": [
    "### After define the model and define the hyperparameters, we need to instantiation the Tuner, `keras_tuners` offers four kinds of optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d669f52-6f04-41ff-9cbf-25e2279fb4e9",
   "metadata": {},
   "source": [
    "1. RandomSearch: The name is the method we using, by the randomly selecting the hyperparameters, good on small seaching area.\n",
    "\n",
    "2. Hyperband: More efficient than the RandomSearch.\n",
    "\n",
    "3. BayesianOptimization: Good performance on continues datasets.\n",
    "\n",
    "4. Sklearn: Can use the keras_tuner on the scikt_learn model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a893098d-cbfa-42c7-b84d-b7c63a458bd2",
   "metadata": {},
   "source": [
    "Now we use the `Hyperband` in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bdad34-e079-41c3-ad13-0183c8d6ac87",
   "metadata": {},
   "source": [
    "**To instantiation the Hyperband tuner, must specify the `hyper model`, the `objective(metrics)` we want to optimize, and the `maximum epoches` of the tuner**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b91b275-ebf7-491f-997e-56fc7f847960",
   "metadata": {},
   "source": [
    "The parameters mean:\n",
    "\n",
    "1. hypermodel: Receive the model we want to optimize, includes `model_builder()` function and `HyperModel()` class objects.\n",
    "\n",
    "2. objective: The metrics we want to optimize, \"val_accuracy\" is for accuracy of the validation dataset.\n",
    "\n",
    "3. max_epochs: The number of epochs if objective haven't improve\n",
    "\n",
    "4. factor: Specify how much percentage we want to store, factor=3, so we divided data into 3 parts, only store 1 part of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfc73a15-9630-42bf-aa3b-6b3312007283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ./untitled_project/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Create the tuner by the model_builder(hp)\n",
    "tuner_1 = kt.Hyperband(\n",
    "    hypermodel=model_builder,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=10,\n",
    "    factor=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a437d322-7ea6-4f57-a886-2ac90f16770a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ./untitled_project/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Create the tuner by the kt.HyperModel():\n",
    "tuner_2 = kt.Hyperband(\n",
    "    hypermodel=MyHyperModel(),\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=15,\n",
    "    factor=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fdeb4c-92eb-460f-9866-52684ca8bee2",
   "metadata": {},
   "source": [
    "#### In the `keras_tuner` and `tensorflow.keras.Module`, the `objective` and the `metrics` all can use `strings`, the metrics/objective using decided by the losses specified in the `compile()`, like if we use `accuracy`, keras will dive in `compile()` and find out which loss function we use, then automatically select the metrics, if use `val_accuracy`, also will automatically find it, but this only works on the `validation dataset` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6c5dcc-25e7-4b18-a8cc-49bc14a4070d",
   "metadata": {},
   "source": [
    "Now we don't want the procedure continues such long, so we add `Early stopping`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c003ec0d-b45e-49c8-b4d3-a4da4813dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e858870c-94ef-46f9-8f70-5879b50cec08",
   "metadata": {},
   "source": [
    "Now we can `do the search`, the search's parameters are the same as the `fit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38f9af35-6a31-46b5-af64-9d6c23395ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 00m 43s]\n",
      "val_accuracy: 0.8535833358764648\n",
      "\n",
      "Best val_accuracy So Far: 0.8940833210945129\n",
      "Total elapsed time: 00h 24m 45s\n"
     ]
    }
   ],
   "source": [
    "tuner_1.search(img_train, lable_train, epochs=50, callbacks=[early_stop], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf716b20-a2a0-4c3e-ab52-40f92e7c2017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 01m 35s]\n",
      "val_accuracy: 0.8864166736602783\n",
      "\n",
      "Best val_accuracy So Far: 0.8870000243186951\n",
      "Total elapsed time: 00h 40m 39s\n"
     ]
    }
   ],
   "source": [
    "tuner_2.search(img_train, lable_train, epochs=50, callbacks=[early_stop], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d081e094-3135-4dc3-9b72-c17303df9c66",
   "metadata": {},
   "source": [
    "### After do the hyperparameter finding, we have find out the hyperparameters, we need store them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bf102b-a3c9-4856-a735-7be7910a605a",
   "metadata": {},
   "source": [
    "keras_tuner will automatically store the hyperparameters, we can use `get_best_hyperparameters()`, to get a list of good hyperparameters.\n",
    "\n",
    "the method `get_best_hyperparameters()` has one parameter, called `num_trials`, this will control the length of the hyperparameter list, so if choose `num_trials=1`, will give a list which only has one parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1daee149-452f-4f88-a7d8-1bf6a97f1d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters at 0x7ffee5f65ad0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameter_model_builder = tuner_1.get_best_hyperparameters(num_trials=1)[0]\n",
    "hyperparameter_model_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8e8d894-10af-4230-a143-d995bdd0bd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters at 0x7ffed8cb6650>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameter_extend_HyperModel = tuner_2.get_best_hyperparameters(num_trials=1)[0]\n",
    "hyperparameter_extend_HyperModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0628132-c4ad-4bbd-ad52-4ca2fe6c48fe",
   "metadata": {},
   "source": [
    "We can take a `look at the parameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1899f65-e3fc-4513-bfd8-c88f903275f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "print(hyperparameter_model_builder.get(\"units\"))\n",
    "print(hyperparameter_model_builder.get(\"learning_rate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3eef58f2-d4dc-4b64-be6f-268ea2993d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "print(hyperparameter_extend_HyperModel.get(\"units\"))\n",
    "print(hyperparameter_extend_HyperModel.get(\"learning_rate\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6c53d-c94a-4eae-9402-fcd6329590d2",
   "metadata": {},
   "source": [
    "### The hyperparameters been stored, now we use them to create a new model, and trained them with these parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ccc6fc4-da6d-4f54-9075-f2d073afb4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tuner_1.hypermodel.build(hyperparameter_model_builder)\n",
    "\n",
    "# Which same as \n",
    "model_1_2 = model_builder(hyperparameter_model_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5971d3c6-9157-482b-a11c-41723462ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tuner_2.hypermodel.build(hyperparameter_extend_HyperModel)\n",
    "\n",
    "#Which same as\n",
    "model_2_2 = MyHyperModel().build(hyperparameter_extend_HyperModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ab183e-1d10-4adb-9d48-ec3656e1a7ff",
   "metadata": {},
   "source": [
    "Now `train the model` which aleady had hyperparameters \n",
    "\n",
    "Because it already has hyperparameters, and it's same as the `compile()` did in specify loss, optimizer and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5731e1fe-0e0c-4569-b73a-20a63873e39c",
   "metadata": {},
   "source": [
    "**The hyperparameters here haven't cover the `epoch`, so we need to try epoch by this hyperparameter unit**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bb643a-e150-42cc-9639-8d982599501b",
   "metadata": {},
   "source": [
    "#### We trained 50 epochs first then find out the best one, after this, we use the `best_epoch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be10cdbb-5d56-4df5-94b2-362e80c92852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9769 - loss: 0.0624 - val_accuracy: 0.8892 - val_loss: 0.6213\n",
      "Epoch 2/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9782 - loss: 0.0599 - val_accuracy: 0.8961 - val_loss: 0.6265\n",
      "Epoch 3/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9781 - loss: 0.0587 - val_accuracy: 0.8944 - val_loss: 0.6166\n",
      "Epoch 4/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9790 - loss: 0.0567 - val_accuracy: 0.8907 - val_loss: 0.6585\n",
      "Epoch 5/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9783 - loss: 0.0588 - val_accuracy: 0.8921 - val_loss: 0.6442\n",
      "Epoch 6/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9795 - loss: 0.0539 - val_accuracy: 0.8973 - val_loss: 0.6304\n",
      "Epoch 7/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9787 - loss: 0.0582 - val_accuracy: 0.8915 - val_loss: 0.6720\n",
      "Epoch 8/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9802 - loss: 0.0531 - val_accuracy: 0.8958 - val_loss: 0.6334\n",
      "Epoch 9/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9794 - loss: 0.0556 - val_accuracy: 0.8892 - val_loss: 0.6876\n",
      "Epoch 10/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9813 - loss: 0.0510 - val_accuracy: 0.8937 - val_loss: 0.6693\n",
      "Epoch 11/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9805 - loss: 0.0533 - val_accuracy: 0.8924 - val_loss: 0.6646\n",
      "Epoch 12/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9814 - loss: 0.0525 - val_accuracy: 0.8935 - val_loss: 0.6992\n",
      "Epoch 13/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9808 - loss: 0.0510 - val_accuracy: 0.8936 - val_loss: 0.6954\n",
      "Epoch 14/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9820 - loss: 0.0487 - val_accuracy: 0.8907 - val_loss: 0.6994\n",
      "Epoch 15/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9818 - loss: 0.0482 - val_accuracy: 0.8926 - val_loss: 0.6980\n",
      "Epoch 16/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9822 - loss: 0.0489 - val_accuracy: 0.8938 - val_loss: 0.7093\n",
      "Epoch 17/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9813 - loss: 0.0510 - val_accuracy: 0.8928 - val_loss: 0.7486\n",
      "Epoch 18/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9826 - loss: 0.0476 - val_accuracy: 0.8950 - val_loss: 0.6914\n",
      "Epoch 19/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9833 - loss: 0.0462 - val_accuracy: 0.8929 - val_loss: 0.7381\n",
      "Epoch 20/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.9837 - loss: 0.0452 - val_accuracy: 0.8935 - val_loss: 0.7562\n",
      "Epoch 21/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9811 - loss: 0.0504 - val_accuracy: 0.8865 - val_loss: 0.7919\n",
      "Epoch 22/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9841 - loss: 0.0449 - val_accuracy: 0.8874 - val_loss: 0.8011\n",
      "Epoch 23/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9830 - loss: 0.0449 - val_accuracy: 0.8947 - val_loss: 0.7623\n",
      "Epoch 24/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9836 - loss: 0.0474 - val_accuracy: 0.8961 - val_loss: 0.7113\n",
      "Epoch 25/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.9850 - loss: 0.0418 - val_accuracy: 0.8892 - val_loss: 0.8202\n",
      "Epoch 26/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9835 - loss: 0.0442 - val_accuracy: 0.8938 - val_loss: 0.7951\n",
      "Epoch 27/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.9847 - loss: 0.0437 - val_accuracy: 0.8971 - val_loss: 0.7789\n",
      "Epoch 28/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9847 - loss: 0.0420 - val_accuracy: 0.8928 - val_loss: 0.7800\n",
      "Epoch 29/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9845 - loss: 0.0446 - val_accuracy: 0.8958 - val_loss: 0.7725\n",
      "Epoch 30/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9852 - loss: 0.0399 - val_accuracy: 0.8962 - val_loss: 0.7703\n",
      "Epoch 31/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9859 - loss: 0.0396 - val_accuracy: 0.8889 - val_loss: 0.7802\n",
      "Epoch 32/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9848 - loss: 0.0420 - val_accuracy: 0.8941 - val_loss: 0.7943\n",
      "Epoch 33/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9852 - loss: 0.0398 - val_accuracy: 0.8940 - val_loss: 0.8204\n",
      "Epoch 34/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9858 - loss: 0.0405 - val_accuracy: 0.8886 - val_loss: 0.8676\n",
      "Epoch 35/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0370 - val_accuracy: 0.8935 - val_loss: 0.8448\n",
      "Epoch 36/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9846 - loss: 0.0430 - val_accuracy: 0.8946 - val_loss: 0.8118\n",
      "Epoch 37/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9868 - loss: 0.0369 - val_accuracy: 0.8883 - val_loss: 0.8762\n",
      "Epoch 38/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9861 - loss: 0.0393 - val_accuracy: 0.8924 - val_loss: 0.8230\n",
      "Epoch 39/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9870 - loss: 0.0361 - val_accuracy: 0.8938 - val_loss: 0.8177\n",
      "Epoch 40/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9859 - loss: 0.0383 - val_accuracy: 0.8917 - val_loss: 0.8530\n",
      "Epoch 41/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9862 - loss: 0.0391 - val_accuracy: 0.8942 - val_loss: 0.8452\n",
      "Epoch 42/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9867 - loss: 0.0380 - val_accuracy: 0.8902 - val_loss: 0.8688\n",
      "Epoch 43/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9866 - loss: 0.0369 - val_accuracy: 0.8916 - val_loss: 0.8917\n",
      "Epoch 44/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0364 - val_accuracy: 0.8932 - val_loss: 0.8350\n",
      "Epoch 45/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9868 - loss: 0.0364 - val_accuracy: 0.8900 - val_loss: 0.9286\n",
      "Epoch 46/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9876 - loss: 0.0351 - val_accuracy: 0.8929 - val_loss: 0.8697\n",
      "Epoch 47/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9873 - loss: 0.0351 - val_accuracy: 0.8942 - val_loss: 0.8438\n",
      "Epoch 48/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9874 - loss: 0.0343 - val_accuracy: 0.8938 - val_loss: 0.8894\n",
      "Epoch 49/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9877 - loss: 0.0337 - val_accuracy: 0.8935 - val_loss: 0.8836\n",
      "Epoch 50/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9866 - loss: 0.0377 - val_accuracy: 0.8958 - val_loss: 0.8773\n",
      "Epoch 1/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9714 - loss: 0.0748 - val_accuracy: 0.8882 - val_loss: 0.5281\n",
      "Epoch 2/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9735 - loss: 0.0705 - val_accuracy: 0.8954 - val_loss: 0.5134\n",
      "Epoch 3/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9735 - loss: 0.0733 - val_accuracy: 0.8949 - val_loss: 0.5693\n",
      "Epoch 4/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9734 - loss: 0.0703 - val_accuracy: 0.8919 - val_loss: 0.5714\n",
      "Epoch 5/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9738 - loss: 0.0701 - val_accuracy: 0.8892 - val_loss: 0.5912\n",
      "Epoch 6/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9747 - loss: 0.0674 - val_accuracy: 0.8871 - val_loss: 0.5792\n",
      "Epoch 7/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9756 - loss: 0.0662 - val_accuracy: 0.8925 - val_loss: 0.5757\n",
      "Epoch 8/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9758 - loss: 0.0651 - val_accuracy: 0.8939 - val_loss: 0.5641\n",
      "Epoch 9/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9753 - loss: 0.0670 - val_accuracy: 0.8941 - val_loss: 0.5815\n",
      "Epoch 10/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.9781 - loss: 0.0583 - val_accuracy: 0.8950 - val_loss: 0.5830\n",
      "Epoch 11/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9762 - loss: 0.0651 - val_accuracy: 0.8979 - val_loss: 0.5931\n",
      "Epoch 12/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9763 - loss: 0.0628 - val_accuracy: 0.8947 - val_loss: 0.6127\n",
      "Epoch 13/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9784 - loss: 0.0597 - val_accuracy: 0.8957 - val_loss: 0.5766\n",
      "Epoch 14/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9766 - loss: 0.0615 - val_accuracy: 0.8924 - val_loss: 0.6009\n",
      "Epoch 15/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9788 - loss: 0.0583 - val_accuracy: 0.8906 - val_loss: 0.6455\n",
      "Epoch 16/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9783 - loss: 0.0584 - val_accuracy: 0.8938 - val_loss: 0.6187\n",
      "Epoch 17/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9797 - loss: 0.0550 - val_accuracy: 0.8875 - val_loss: 0.6822\n",
      "Epoch 18/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9798 - loss: 0.0554 - val_accuracy: 0.8894 - val_loss: 0.6797\n",
      "Epoch 19/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9796 - loss: 0.0558 - val_accuracy: 0.8928 - val_loss: 0.6201\n",
      "Epoch 20/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9800 - loss: 0.0566 - val_accuracy: 0.8868 - val_loss: 0.6983\n",
      "Epoch 21/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9815 - loss: 0.0506 - val_accuracy: 0.8934 - val_loss: 0.6525\n",
      "Epoch 22/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9800 - loss: 0.0560 - val_accuracy: 0.8871 - val_loss: 0.6864\n",
      "Epoch 23/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9814 - loss: 0.0527 - val_accuracy: 0.8861 - val_loss: 0.7128\n",
      "Epoch 24/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9817 - loss: 0.0511 - val_accuracy: 0.8913 - val_loss: 0.6847\n",
      "Epoch 25/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9804 - loss: 0.0534 - val_accuracy: 0.8851 - val_loss: 0.7246\n",
      "Epoch 26/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - accuracy: 0.9819 - loss: 0.0495 - val_accuracy: 0.8913 - val_loss: 0.7021\n",
      "Epoch 27/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9821 - loss: 0.0494 - val_accuracy: 0.8930 - val_loss: 0.6749\n",
      "Epoch 28/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9821 - loss: 0.0483 - val_accuracy: 0.8862 - val_loss: 0.7539\n",
      "Epoch 29/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9822 - loss: 0.0495 - val_accuracy: 0.8919 - val_loss: 0.7110\n",
      "Epoch 30/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0485 - val_accuracy: 0.8926 - val_loss: 0.7167\n",
      "Epoch 31/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9821 - loss: 0.0477 - val_accuracy: 0.8967 - val_loss: 0.6957\n",
      "Epoch 32/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9834 - loss: 0.0478 - val_accuracy: 0.8923 - val_loss: 0.7211\n",
      "Epoch 33/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9843 - loss: 0.0449 - val_accuracy: 0.8954 - val_loss: 0.7013\n",
      "Epoch 34/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9832 - loss: 0.0470 - val_accuracy: 0.8917 - val_loss: 0.7201\n",
      "Epoch 35/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9835 - loss: 0.0458 - val_accuracy: 0.8930 - val_loss: 0.7422\n",
      "Epoch 36/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9826 - loss: 0.0489 - val_accuracy: 0.8906 - val_loss: 0.7380\n",
      "Epoch 37/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9837 - loss: 0.0453 - val_accuracy: 0.8917 - val_loss: 0.7075\n",
      "Epoch 38/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - accuracy: 0.9842 - loss: 0.0422 - val_accuracy: 0.8890 - val_loss: 0.7470\n",
      "Epoch 39/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.9850 - loss: 0.0411 - val_accuracy: 0.8946 - val_loss: 0.7437\n",
      "Epoch 40/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9846 - loss: 0.0443 - val_accuracy: 0.8938 - val_loss: 0.7579\n",
      "Epoch 41/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9855 - loss: 0.0412 - val_accuracy: 0.8942 - val_loss: 0.7339\n",
      "Epoch 42/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9853 - loss: 0.0435 - val_accuracy: 0.8892 - val_loss: 0.8616\n",
      "Epoch 43/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9852 - loss: 0.0407 - val_accuracy: 0.8943 - val_loss: 0.7666\n",
      "Epoch 44/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9848 - loss: 0.0424 - val_accuracy: 0.8945 - val_loss: 0.7843\n",
      "Epoch 45/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9861 - loss: 0.0375 - val_accuracy: 0.8937 - val_loss: 0.7644\n",
      "Epoch 46/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9846 - loss: 0.0448 - val_accuracy: 0.8886 - val_loss: 0.8347\n",
      "Epoch 47/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9860 - loss: 0.0409 - val_accuracy: 0.8891 - val_loss: 0.8284\n",
      "Epoch 48/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9846 - loss: 0.0456 - val_accuracy: 0.8934 - val_loss: 0.8117\n",
      "Epoch 49/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9879 - loss: 0.0340 - val_accuracy: 0.8882 - val_loss: 0.8108\n",
      "Epoch 50/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9860 - loss: 0.0382 - val_accuracy: 0.8900 - val_loss: 0.8111\n",
      "Best epoch of model_1: 6\n",
      "Best epoch of model_1_2: 11\n"
     ]
    }
   ],
   "source": [
    "# We use model_1 for whole training, the model_2 for best_epoch\n",
    "\n",
    "history_1 = model_1.fit(img_train, lable_train, epochs=50, validation_split=0.2)\n",
    "history_1_2 = model_1_2.fit(img_train,lable_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "# from history get the model's accuracy changing\n",
    "val_acc_model_1 = history_1.history[\"val_accuracy\"]\n",
    "val_acc_mdoel_1_2 = history_1_2.history[\"val_accuracy\"]\n",
    "\n",
    "# find the best parameter index and plus one as epoch\n",
    "best_epoch_1 = val_acc_model_1.index(max(val_acc_model_1)) + 1 \n",
    "best_epoch_1_2 = val_acc_mdoel_1_2.index(max(val_acc_mdoel_1_2)) + 1\n",
    "\n",
    "print(f\"Best epoch of model_1: {best_epoch_1}\")\n",
    "print(f\"Best epoch of model_1_2: {best_epoch_1_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1571f269-9b98-4ebc-b11d-897f43707072",
   "metadata": {},
   "source": [
    "#### Now we trained the model as the best_epoch we find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2abc9030-788f-4d72-87dd-d81fd1f2ee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7957 - loss: 0.5716 - val_accuracy: 0.8397 - val_loss: 0.4396\n",
      "Epoch 2/6\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8427 - loss: 0.4335 - val_accuracy: 0.8584 - val_loss: 0.3885\n",
      "Epoch 3/6\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8560 - loss: 0.4000 - val_accuracy: 0.8732 - val_loss: 0.3552\n",
      "Epoch 4/6\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8611 - loss: 0.3786 - val_accuracy: 0.8758 - val_loss: 0.3448\n",
      "Epoch 5/6\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8662 - loss: 0.3640 - val_accuracy: 0.8757 - val_loss: 0.3408\n",
      "Epoch 6/6\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8716 - loss: 0.3467 - val_accuracy: 0.8802 - val_loss: 0.3294\n",
      "Epoch 1/11\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7970 - loss: 0.5692 - val_accuracy: 0.8464 - val_loss: 0.4113\n",
      "Epoch 2/11\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8428 - loss: 0.4331 - val_accuracy: 0.8547 - val_loss: 0.3920\n",
      "Epoch 3/11\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8546 - loss: 0.3987 - val_accuracy: 0.8653 - val_loss: 0.3729\n",
      "Epoch 4/11\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8618 - loss: 0.3777 - val_accuracy: 0.8791 - val_loss: 0.3381\n",
      "Epoch 5/11\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8678 - loss: 0.3599 - val_accuracy: 0.8727 - val_loss: 0.3456\n",
      "Epoch 6/11\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8715 - loss: 0.3478 - val_accuracy: 0.8783 - val_loss: 0.3409\n",
      "Epoch 7/11\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8742 - loss: 0.3394 - val_accuracy: 0.8816 - val_loss: 0.3301\n",
      "Epoch 8/11\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8771 - loss: 0.3303 - val_accuracy: 0.8756 - val_loss: 0.3481\n",
      "Epoch 9/11\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8797 - loss: 0.3231 - val_accuracy: 0.8817 - val_loss: 0.3301\n",
      "Epoch 10/11\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8837 - loss: 0.3134 - val_accuracy: 0.8827 - val_loss: 0.3234\n",
      "Epoch 11/11\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8861 - loss: 0.3070 - val_accuracy: 0.8848 - val_loss: 0.3249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7ffea1b90890>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(img_train, lable_train, epochs=best_epoch_1, validation_split=0.2)\n",
    "model_2_2.fit(img_train, lable_train, epochs=best_epoch_1_2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32faa843-6302-404d-8f10-906b236a6b0c",
   "metadata": {},
   "source": [
    "Now do the `evaluate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b7b2b12-adf9-4489-95ce-91f8ea60c0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8708 - loss: 0.3620\n"
     ]
    }
   ],
   "source": [
    "evaluation = model_2.evaluate(x=img_test, y=lable_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0319cdeb-1a1a-4575-ac28-32c9d2f322e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The evaluation result(loss, accuracy) is: [0.36203888058662415, 0.8708000183105469]\n"
     ]
    }
   ],
   "source": [
    "print(f\"The evaluation result(loss, accuracy) is: {evaluation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797225cf-aeb5-4710-8cb3-84fba0809217",
   "metadata": {},
   "source": [
    "### Now we have learned the searching of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b99bc5-ace2-444e-9773-11912df01e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
